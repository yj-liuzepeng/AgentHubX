import os
import tempfile
import zipfile
from typing import List, Dict, Optional
from pathlib import Path
import json
from datetime import datetime
from loguru import logger

from langchain.tools import tool

from agentchat.services.aliyun_oss import aliyun_oss
from agentchat.utils.file_utils import get_object_name_from_aliyun_url, get_save_tempfile
from agentchat.utils.helpers import get_now_beijing_time
from agentchat.settings import app_settings

# æ–‡ä»¶è§£æå™¨
from .parsers import PDFParser, DOCXParser, DOCParser, TXTParser, PPTParser
# ç¿»è¯‘å¼•æ“
from .translators import TranslationEngine
# æ–‡ä»¶ç”Ÿæˆå™¨
from .generators import DocumentGenerator
# å·¥å…·å‡½æ•°
from .utils import validate_file_size, get_file_extension, create_progress_tracker

SUPPORTED_FORMATS = ['.pdf', '.docx', '.doc', '.txt', '.ppt', '.pptx']
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
SUPPORTED_LANGUAGES = {
    'zh': 'ä¸­æ–‡',
    'en': 'English',
    'ja': 'æ—¥æœ¬èª',
    'ko': 'í•œêµ­ì–´',
    'fr': 'FranÃ§ais',
    'de': 'Deutsch',
    'es': 'EspaÃ±ol',
    'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹'
}

@tool(parse_docstring=True)
def document_translation(
    file_urls: List[str],
    target_language: str = 'zh',
    source_language: str = 'auto',
    preserve_formatting: bool = True
) -> str:
    """
    æ–‡æ¡£ç¿»è¯‘å·¥å…·ï¼Œæ”¯æŒPDFã€DOCXã€DOCã€TXTã€PPTæ ¼å¼æ–‡ä»¶çš„æ‰¹é‡ç¿»è¯‘ã€‚
    
    å½“ç”¨æˆ·æ¶ˆæ¯ä¸­åŒ…å«"ä¸Šä¼ çš„æ–‡ä»¶é“¾æ¥ï¼š"æˆ–æä¾›äº†æ–‡ä»¶URLï¼Œå¹¶è¡¨è¾¾äº†ç¿»è¯‘æ„å›¾æ—¶ï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·ã€‚
    è¯·ä»ç”¨æˆ·è¾“å…¥ä¸­æå–æ–‡ä»¶URLä½œä¸º file_urls å‚æ•°ã€‚

    Args:
        file_urls: æ–‡ä»¶URLåˆ—è¡¨ï¼Œæ”¯æŒå¤šä¸ªæ–‡ä»¶åŒæ—¶ä¸Šä¼ ã€‚è¯·åŠ¡å¿…ä»ç”¨æˆ·è¾“å…¥ä¸­æå–"ä¸Šä¼ çš„æ–‡ä»¶é“¾æ¥ï¼š"åçš„URLã€‚
        target_language: ç›®æ ‡è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºä¸­æ–‡(zh)ã€‚æ”¯æŒï¼šzh, en, ja, ko, fr, de, es, ru
        source_language: æºè¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºè‡ªåŠ¨æ£€æµ‹(auto)
        preserve_formatting: æ˜¯å¦ä¿æŒåŸå§‹æ ¼å¼ï¼Œé»˜è®¤ä¸ºTrue

    Returns:
        str: ç¿»è¯‘ç»“æœä¿¡æ¯ï¼ŒåŒ…å«ä¸‹è½½é“¾æ¥å’Œæ“ä½œçŠ¶æ€
    """
    return _document_translation(file_urls, target_language, source_language, preserve_formatting)

def _document_translation(
    file_urls: List[str],
    target_language: str,
    source_language: str,
    preserve_formatting: bool
) -> str:
    """æ‰§è¡Œæ–‡æ¡£ç¿»è¯‘çš„æ ¸å¿ƒå‡½æ•°"""
    
    # éªŒè¯è¾“å…¥å‚æ•°
    if not file_urls:
        return "é”™è¯¯ï¼šæœªæä¾›æ–‡ä»¶é“¾æ¥ï¼Œè¯·ä¸Šä¼ æ–‡ä»¶åå†è¯•ã€‚"
    
    if target_language not in SUPPORTED_LANGUAGES:
        return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„ç›®æ ‡è¯­è¨€ '{target_language}'ã€‚æ”¯æŒçš„è¯­è¨€ï¼š{', '.join(SUPPORTED_LANGUAGES.keys())}"
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        progress_tracker = create_progress_tracker()
        
        # è·å–æ–‡æ¡£ç¿»è¯‘é…ç½®
        translation_config = getattr(app_settings.tools, 'document_translation', {})
        translation_engine = TranslationEngine(config=translation_config)
        
        doc_generator = DocumentGenerator()
        
        # æ–‡ä»¶å¤„ç†ç»“æœ
        processed_files = []
        failed_files = []
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for idx, file_url in enumerate(file_urls):
            try:
                # æ›´æ–°è¿›åº¦
                progress_tracker.update(f"æ­£åœ¨å¤„ç†ç¬¬ {idx + 1}/{len(file_urls)} ä¸ªæ–‡ä»¶...")
                
                # ä¸‹è½½å’ŒéªŒè¯æ–‡ä»¶
                file_info = download_and_validate_file(file_url)
                if not file_info:
                    failed_files.append(f"æ–‡ä»¶ {file_url}: ä¸‹è½½æˆ–éªŒè¯å¤±è´¥")
                    continue
                
                # è§£ææ–‡ä»¶
                progress_tracker.update(f"æ­£åœ¨è§£æ {file_info['filename']}...")
                parsed_content = parse_document(file_info)
                if not parsed_content:
                    failed_files.append(f"æ–‡ä»¶ {file_info['filename']}: è§£æå¤±è´¥")
                    continue
                
                # ç¿»è¯‘å†…å®¹
                progress_tracker.update(f"æ­£åœ¨ç¿»è¯‘ {file_info['filename']}...")
                translated_content = translate_content(
                    parsed_content, 
                    source_language, 
                    target_language,
                    translation_engine
                )
                
                # ç”Ÿæˆç¿»è¯‘æ–‡æ¡£
                progress_tracker.update(f"æ­£åœ¨ç”Ÿæˆç¿»è¯‘æ–‡æ¡£ {file_info['filename']}...")
                output_file = generate_translated_document(
                    file_info,
                    translated_content,
                    target_language,
                    preserve_formatting,
                    doc_generator
                )
                
                # ä¸Šä¼ ç¿»è¯‘åçš„æ–‡ä»¶
                progress_tracker.update(f"æ­£åœ¨ä¸Šä¼ ç¿»è¯‘æ–‡æ¡£ {file_info['filename']}...")
                download_url = upload_translated_file(output_file, file_info)
                
                processed_files.append({
                    'original_name': file_info['filename'],
                    'translated_url': download_url,
                    'target_language': SUPPORTED_LANGUAGES[target_language]
                })
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                cleanup_temp_files(file_info)
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {file_url} æ—¶å‡ºé”™: {str(e)}")
                failed_files.append(f"æ–‡ä»¶ {file_url}: {str(e)}")
                continue
        
        # ç”Ÿæˆç»“æœä¿¡æ¯
        return generate_result_message(processed_files, failed_files, progress_tracker)
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {str(e)}")
        return f"æ–‡æ¡£ç¿»è¯‘å¤±è´¥ï¼š{str(e)}"

def download_and_validate_file(file_url: str) -> Optional[Dict]:
    """ä¸‹è½½å¹¶éªŒè¯æ–‡ä»¶"""
    try:
        # ä»é˜¿é‡Œäº‘ä¸‹è½½æ–‡ä»¶
        object_name = get_object_name_from_aliyun_url(file_url)
        file_name = file_url.split("/")[-1]
        file_path = get_save_tempfile(file_name)
        
        # ä¸‹è½½æ–‡ä»¶
        aliyun_oss.download_file(object_name, file_path)
        
        # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.isfile(file_path):
            return None
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size > MAX_FILE_SIZE:
            os.remove(file_path)
            return None
        
        # éªŒè¯æ–‡ä»¶æ ¼å¼
        file_ext = get_file_extension(file_path)
        if file_ext.lower() not in SUPPORTED_FORMATS:
            os.remove(file_path)
            return None
        
        return {
            'url': file_url,
            'filename': file_name,
            'filepath': file_path,
            'extension': file_ext.lower(),
            'size': file_size
        }
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸‹è½½éªŒè¯å¤±è´¥: {str(e)}")
        return None

def parse_document(file_info: Dict) -> Optional[Dict]:
    """è§£ææ–‡æ¡£å†…å®¹"""
    try:
        file_path = file_info['filepath']
        file_ext = file_info['extension']
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è§£æå™¨
        if file_ext == '.pdf':
            parser = PDFParser()
        elif file_ext == '.docx':
            parser = DOCXParser()
        elif file_ext == '.doc':
            parser = DOCParser()
        elif file_ext == '.txt':
            parser = TXTParser()
        elif file_ext in ['.ppt', '.pptx']:
            parser = PPTParser()
        else:
            return None
        
        return parser.parse(file_path)
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£è§£æå¤±è´¥: {str(e)}")
        return None

def translate_content(
    content: Dict, 
    source_lang: str, 
    target_lang: str, 
    translator: TranslationEngine
) -> Dict:
    """ç¿»è¯‘æ–‡æ¡£å†…å®¹"""
    try:
        translated_content = content.copy()
        has_structural_translation = False
        
        # 1. ç¿»è¯‘ç»“æ„åŒ–å†…å®¹
        
        # ç¿»è¯‘ pages (PDF)
        if 'pages' in content and content['pages']:
            translated_pages = []
            for page in content['pages']:
                new_page = page.copy()
                if 'text' in page and page['text']:
                    new_page['text'] = translator.translate(
                        page['text'],
                        source_language=source_lang,
                        target_language=target_lang
                    )
                translated_pages.append(new_page)
            translated_content['pages'] = translated_pages
            has_structural_translation = True
            
            # ä»ç¿»è¯‘åçš„é¡µé¢é‡æ„å…¨æ–‡æ–‡æœ¬
            translated_content['text'] = '\n\n'.join([p.get('text', '') for p in translated_pages])

        # ç¿»è¯‘ paragraphs (DOCX/DOC)
        if 'paragraphs' in content and content['paragraphs']:
            translated_paragraphs = []
            full_text_parts = []
            
            for para in content['paragraphs']:
                new_para = para.copy()
                
                # ç¿»è¯‘æ®µè½æ–‡æœ¬
                if 'text' in para and para['text']:
                    new_para['text'] = translator.translate(
                        para['text'],
                        source_language=source_lang,
                        target_language=target_lang
                    )
                
                # ç¿»è¯‘ runs (ç”¨äºä¿ç•™æ ·å¼)
                if 'runs' in para and para['runs']:
                    new_runs = []
                    for run in para['runs']:
                        new_run = run.copy()
                        if 'text' in run and run['text']:
                            new_run['text'] = translator.translate(
                                run['text'],
                                source_language=source_lang,
                                target_language=target_lang
                            )
                        new_runs.append(new_run)
                    new_para['runs'] = new_runs
                    
                    # å¦‚æœæœ‰ runsï¼Œæ®µè½æ–‡æœ¬åº”è¯¥æ˜¯ runs çš„ç»„åˆ
                    # ä½†ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬ä¼˜å…ˆä¿¡ä»» runs çš„ç¿»è¯‘ç»“æœç»„åˆï¼ˆå¦‚æœæœ‰ï¼‰
                    # æˆ–è€…ä¿æŒ new_para['text'] çš„ç‹¬ç«‹ç¿»è¯‘ç»“æœ
                
                translated_paragraphs.append(new_para)
                if new_para.get('text'):
                    full_text_parts.append(new_para['text'])
            
            translated_content['paragraphs'] = translated_paragraphs
            has_structural_translation = True
            
            # æ›´æ–°å…¨æ–‡æ–‡æœ¬ (å¦‚æœæ²¡æœ‰ pages æ›´æ–°è¿‡)
            if 'pages' not in content:
                translated_content['text'] = '\n\n'.join(full_text_parts)

        # ç¿»è¯‘ tables (DOCX)
        if 'tables' in content and content['tables']:
            translated_tables = []
            for table in content['tables']:
                new_table = []
                for row in table:
                    new_row = []
                    for cell_text in row:
                        if cell_text and isinstance(cell_text, str) and cell_text.strip():
                            new_cell_text = translator.translate(
                                cell_text,
                                source_language=source_lang,
                                target_language=target_lang
                            )
                            new_row.append(new_cell_text)
                        else:
                            new_row.append(cell_text)
                    new_table.append(new_row)
                translated_tables.append(new_table)
            translated_content['tables'] = translated_tables
            # è¡¨æ ¼é€šå¸¸ä¸è®¡å…¥ content['text'] çš„ä¸»è¦éƒ¨åˆ†ï¼Œæˆ–è€…è§£æå™¨å·²å¤„ç†
        
        # 2. å¦‚æœæ²¡æœ‰ç»“æ„åŒ–å†…å®¹ï¼Œç¿»è¯‘å…¨æ–‡æ–‡æœ¬ (å¦‚ TXT)
        if not has_structural_translation:
            text_content = content.get('text', '')
            if text_content:
                translated_text = translator.translate(
                    text_content,
                    source_language=source_lang,
                    target_language=target_lang
                )
                translated_content['text'] = translated_text
        
        translated_content['translated_language'] = target_lang
        
        return translated_content
        
    except Exception as e:
        logger.error(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
        raise e

def generate_translated_document(
    file_info: Dict,
    translated_content: Dict,
    target_language: str,
    preserve_formatting: bool,
    generator: DocumentGenerator
) -> str:
    """ç”Ÿæˆç¿»è¯‘åçš„æ–‡æ¡£"""
    try:
        original_path = file_info['filepath']
        file_ext = file_info['extension']
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_dir = tempfile.mkdtemp()
        base_name = os.path.splitext(file_info['filename'])[0]
        output_filename = f"{base_name}_translated_{target_language}{file_ext}"
        output_path = os.path.join(output_dir, output_filename)
        
        # ç”Ÿæˆæ–‡æ¡£
        generator.generate(
            translated_content,
            output_path,
            original_path,
            preserve_formatting
        )
        
        return output_path
        
    except Exception as e:
        logger.error(f"æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {str(e)}")
        raise e

def upload_translated_file(output_file: str, file_info: Dict) -> str:
    """ä¸Šä¼ ç¿»è¯‘åçš„æ–‡ä»¶"""
    try:
        # ç”Ÿæˆé˜¿é‡Œäº‘å¯¹è±¡åç§°
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        output_filename = os.path.basename(output_file)
        oss_object_name = f"document_translation/{timestamp}_{output_filename}"
        
        # ä¸Šä¼ åˆ°é˜¿é‡Œäº‘
        aliyun_oss.upload_local_file(oss_object_name, output_file)
        
        # ç”Ÿæˆç­¾åURL
        download_url = aliyun_oss.sign_url_for_get(oss_object_name)
        
        return download_url
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
        raise e

def cleanup_temp_files(file_info: Dict):
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    try:
        if os.path.exists(file_info['filepath']):
            os.remove(file_info['filepath'])
    except Exception as e:
        logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")

def generate_result_message(
    processed_files: List[Dict], 
    failed_files: List[str], 
    progress_tracker
) -> str:
    """ç”Ÿæˆç»“æœä¿¡æ¯"""
    
    if not processed_files and not failed_files:
        return "æ²¡æœ‰æ–‡ä»¶è¢«å¤„ç†ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå¤§å°é™åˆ¶ã€‚"
    
    result_parts = []
    
    # æˆåŠŸå¤„ç†çš„æ–‡ä»¶
    if processed_files:
        result_parts.append("âœ… ç¿»è¯‘å®Œæˆï¼")
        result_parts.append("")
        
        for file_info in processed_files:
            result_parts.append(
                f"ğŸ“„ {file_info['original_name']} -> {file_info['target_language']}"
            )
            result_parts.append(f"[ç‚¹å‡»ä¸‹è½½ç¿»è¯‘æ–‡ä»¶]({file_info['translated_url']})")
            result_parts.append("")
    
    # å¤±è´¥çš„æ–‡ä»¶
    if failed_files:
        result_parts.append("âŒ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š")
        for failure in failed_files:
            result_parts.append(f"  â€¢ {failure}")
        result_parts.append("")
    
    # æ·»åŠ æ—¶é—´é™åˆ¶æç¤º
    now_time = get_now_beijing_time(delta=1)
    result_parts.append(f"â° è¯·åœ¨ {now_time} å‰ä¸‹è½½æ–‡ä»¶ï¼Œè¶…è¿‡æ—¶é—´é“¾æ¥å°†å¤±æ•ˆ")
    
    return "\n".join(result_parts)