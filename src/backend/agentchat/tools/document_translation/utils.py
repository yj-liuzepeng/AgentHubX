"""
å·¥å…·å‡½æ•°æ¨¡å—
æä¾›å„ç§å®ç”¨å·¥å…·å‡½æ•°
"""

import os
import re
import time
import mimetypes
from typing import Dict, List, Optional, Any
from pathlib import Path
from loguru import logger

class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, total_steps: int = 100):
        self.total_steps = total_steps
        self.current_step = 0
        self.start_time = time.time()
        self.messages = []
        
    def update(self, message: str, steps: int = 1):
        """æ›´æ–°è¿›åº¦"""
        self.current_step += steps
        self.messages.append({
            'time': time.time(),
            'message': message,
            'progress': min(100, (self.current_step / self.total_steps) * 100)
        })
        logger.info(f"[{self.get_progress_percentage():.1f}%] {message}")
    
    def get_progress_percentage(self) -> float:
        """è·å–è¿›åº¦ç™¾åˆ†æ¯”"""
        return min(100, (self.current_step / self.total_steps) * 100)
    
    def get_elapsed_time(self) -> float:
        """è·å–å·²ç”¨æ—¶é—´"""
        return time.time() - self.start_time
    
    def get_estimated_time_remaining(self) -> float:
        """è·å–é¢„è®¡å‰©ä½™æ—¶é—´"""
        if self.current_step == 0:
            return 0
        
        elapsed = self.get_elapsed_time()
        rate = self.current_step / elapsed
        remaining_steps = self.total_steps - self.current_step
        
        return remaining_steps / rate if rate > 0 else 0
    
    def get_summary(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦æ‘˜è¦"""
        return {
            'progress_percentage': self.get_progress_percentage(),
            'elapsed_time': self.get_elapsed_time(),
            'estimated_time_remaining': self.get_estimated_time_remaining(),
            'current_step': self.current_step,
            'total_steps': self.total_steps,
            'latest_message': self.messages[-1]['message'] if self.messages else '',
            'total_messages': len(self.messages)
        }

def validate_file_size(file_path: str, max_size_mb: int = 50) -> bool:
    """
    éªŒè¯æ–‡ä»¶å¤§å°
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        max_size_mb: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    
    Returns:
        æ–‡ä»¶æ˜¯å¦åœ¨å¤§å°é™åˆ¶å†…
    """
    try:
        if not os.path.exists(file_path):
            return False
        
        file_size = os.path.getsize(file_path)
        max_size_bytes = max_size_mb * 1024 * 1024
        
        return file_size <= max_size_bytes
        
    except Exception as e:
        logger.error(f"éªŒè¯æ–‡ä»¶å¤§å°å¤±è´¥: {str(e)}")
        return False

def get_file_extension(file_path: str) -> str:
    """
    è·å–æ–‡ä»¶æ‰©å±•å
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ–‡ä»¶æ‰©å±•åï¼ˆåŒ…å«ç‚¹å·ï¼‰
    """
    return Path(file_path).suffix.lower()

def get_file_mime_type(file_path: str) -> str:
    """
    è·å–æ–‡ä»¶çš„MIMEç±»å‹
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        MIMEç±»å‹
    """
    try:
        mime_type, _ = mimetypes.guess_type(file_path)
        return mime_type or 'application/octet-stream'
    except Exception as e:
        logger.error(f"è·å–MIMEç±»å‹å¤±è´¥: {str(e)}")
        return 'application/octet-stream'

def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸åˆæ³•å­—ç¬¦
    
    Args:
        filename: åŸå§‹æ–‡ä»¶å
    
    Returns:
        æ¸…ç†åçš„æ–‡ä»¶å
    """
    # ç§»é™¤æˆ–æ›¿æ¢ä¸åˆæ³•å­—ç¬¦
    invalid_chars = r'[<>:"/\\|?*]'
    filename = re.sub(invalid_chars, '_', filename)
    
    # ç§»é™¤æ§åˆ¶å­—ç¬¦
    filename = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', filename)
    
    # é™åˆ¶é•¿åº¦
    max_length = 255
    if len(filename) > max_length:
        name, ext = os.path.splitext(filename)
        filename = name[:max_length - len(ext)] + ext
    
    return filename.strip()

def create_temp_directory(prefix: str = "doc_translation_") -> str:
    """
    åˆ›å»ºä¸´æ—¶ç›®å½•
    
    Args:
        prefix: ç›®å½•åå‰ç¼€
    
    Returns:
        ä¸´æ—¶ç›®å½•è·¯å¾„
    """
    try:
        temp_dir = tempfile.mkdtemp(prefix=prefix)
        logger.info(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")
        return temp_dir
        
    except Exception as e:
        logger.error(f"åˆ›å»ºä¸´æ—¶ç›®å½•å¤±è´¥: {str(e)}")
        raise

def cleanup_temp_files(file_paths: List[str]) -> bool:
    """
    æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    
    Args:
        file_paths: è¦æ¸…ç†çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    
    Returns:
        æ˜¯å¦å…¨éƒ¨æ¸…ç†æˆåŠŸ
    """
    success_count = 0
    
    for file_path in file_paths:
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                success_count += 1
                logger.debug(f"æ¸…ç†æ–‡ä»¶æˆåŠŸ: {file_path}")
        except Exception as e:
            logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
    
    return success_count == len(file_paths)

def format_file_size(size_bytes: int) -> str:
    """
    æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
    
    Args:
        size_bytes: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    
    Returns:
        æ ¼å¼åŒ–çš„å¤§å°å­—ç¬¦ä¸²
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    
    while size_bytes >= 1024 and i < len(size_names) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.1f} {size_names[i]}"

def estimate_translation_time(text_length: int, complexity: str = 'normal') -> float:
    """
    ä¼°ç®—ç¿»è¯‘æ‰€éœ€æ—¶é—´
    
    Args:
        text_length: æ–‡æœ¬é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
        complexity: å¤æ‚åº¦ï¼ˆsimple, normal, complexï¼‰
    
    Returns:
        é¢„è®¡æ—¶é—´ï¼ˆç§’ï¼‰
    """
    # åŸºç¡€æ—¶é—´ï¼ˆæ¯1000å­—ç¬¦ï¼‰
    base_time_per_1000_chars = {
        'simple': 2.0,    # ç®€å•æ–‡æœ¬
        'normal': 3.0,    # æ™®é€šæ–‡æœ¬
        'complex': 5.0    # å¤æ‚æ–‡æœ¬ï¼ˆä¸“ä¸šæœ¯è¯­å¤šï¼‰
    }
    
    base_time = base_time_per_1000_chars.get(complexity, 3.0)
    
    # è®¡ç®—æ€»æ—¶é—´
    estimated_time = (text_length / 1000.0) * base_time
    
    # æ·»åŠ ç½‘ç»œå»¶è¿Ÿ
    network_delay = 1.0
    
    # æ·»åŠ å¤„ç†å¼€é”€
    processing_overhead = 2.0
    
    total_time = estimated_time + network_delay + processing_overhead
    
    return max(1.0, total_time)  # æœ€å°‘1ç§’

def split_text_for_translation(text: str, max_chunk_size: int = 5000) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²æˆé€‚åˆç¿»è¯‘çš„å—
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_chunk_size: æœ€å¤§å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
    
    Returns:
        æ–‡æœ¬å—åˆ—è¡¨
    """
    if len(text) <= max_chunk_size:
        return [text]
    
    chunks = []
    current_chunk = ""
    
    # æŒ‰å¥å­åˆ†å‰²
    sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]\s*', text)
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        # æ·»åŠ æ ‡ç‚¹ç¬¦å·
        if sentence:
            sentence += ". "
        
        # æ£€æŸ¥å½“å‰å—å¤§å°
        if len(current_chunk) + len(sentence) <= max_chunk_size:
            current_chunk += sentence
        else:
            # ä¿å­˜å½“å‰å—
            if current_chunk:
                chunks.append(current_chunk.strip())
            
            # å¼€å§‹æ–°å—
            if len(sentence) <= max_chunk_size:
                current_chunk = sentence
            else:
                # å¦‚æœå•ä¸ªå¥å­å°±è¶…è¿‡é™åˆ¶ï¼ŒæŒ‰æ ‡ç‚¹åˆ†å‰²
                sub_sentences = re.split(r'[,;ï¼Œï¼›]\s*', sentence)
                sub_chunk = ""
                for sub_sentence in sub_sentences:
                    if len(sub_chunk) + len(sub_sentence) <= max_chunk_size:
                        sub_chunk += sub_sentence + ", "
                    else:
                        if sub_chunk:
                            chunks.append(sub_chunk.strip())
                        sub_chunk = sub_sentence + ", "
                
                if sub_chunk:
                    chunks.append(sub_chunk.strip())
                current_chunk = ""
    
    # æ·»åŠ æœ€åä¸€ä¸ªå—
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

def create_progress_tracker(total_steps: int = 100) -> ProgressTracker:
    """
    åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
    
    Args:
        total_steps: æ€»æ­¥éª¤æ•°
    
    Returns:
        ProgressTrackerå®ä¾‹
    """
    return ProgressTracker(total_steps)

def validate_language_code(language_code: str, supported_languages: Dict[str, str]) -> bool:
    """
    éªŒè¯è¯­è¨€ä»£ç æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        language_code: è¯­è¨€ä»£ç 
        supported_languages: æ”¯æŒçš„è¯­è¨€å­—å…¸
    
    Returns:
        è¯­è¨€ä»£ç æ˜¯å¦æœ‰æ•ˆ
    """
    return language_code in supported_languages

def get_language_name(language_code: str, supported_languages: Dict[str, str]) -> str:
    """
    è·å–è¯­è¨€åç§°
    
    Args:
        language_code: è¯­è¨€ä»£ç 
        supported_languages: æ”¯æŒçš„è¯­è¨€å­—å…¸
    
    Returns:
        è¯­è¨€åç§°
    """
    return supported_languages.get(language_code, language_code)

def format_translation_result(
    processed_files: List[Dict],
    failed_files: List[str],
    total_time: float
) -> str:
    """
    æ ¼å¼åŒ–ç¿»è¯‘ç»“æœä¿¡æ¯
    
    Args:
        processed_files: æˆåŠŸå¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
        failed_files: å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨
        total_time: æ€»è€—æ—¶
    
    Returns:
        æ ¼å¼åŒ–åçš„ç»“æœå­—ç¬¦ä¸²
    """
    result_parts = []
    
    # æˆåŠŸå¤„ç†çš„æ–‡ä»¶
    if processed_files:
        result_parts.append("âœ… ç¿»è¯‘å®Œæˆï¼")
        result_parts.append("")
        
        for file_info in processed_files:
            result_parts.append(f"ğŸ“„ {file_info['original_name']}")
            result_parts.append(f"   ç›®æ ‡è¯­è¨€: {file_info['target_language']}")
            result_parts.append(f"   ä¸‹è½½é“¾æ¥: {file_info['translated_url']}")
            result_parts.append("")
    
    # å¤±è´¥çš„æ–‡ä»¶
    if failed_files:
        result_parts.append("âŒ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š")
        for failure in failed_files:
            result_parts.append(f"  â€¢ {failure}")
        result_parts.append("")
    
    # ç»Ÿè®¡ä¿¡æ¯
    result_parts.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    result_parts.append(f"   æ€»æ–‡ä»¶æ•°: {len(processed_files) + len(failed_files)}")
    result_parts.append(f"   æˆåŠŸ: {len(processed_files)}")
    result_parts.append(f"   å¤±è´¥: {len(failed_files)}")
    result_parts.append(f"   æ€»è€—æ—¶: {total_time:.1f}ç§’")
    
    return "\n".join(result_parts)

import tempfile